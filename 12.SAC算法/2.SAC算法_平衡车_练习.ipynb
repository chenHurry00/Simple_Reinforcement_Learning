{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03780822, -0.02429027,  0.02112488, -0.02773819], dtype=float32)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "\n",
    "#定义环境\n",
    "class MyWrapper(gym.Wrapper):\n",
    "\n",
    "    def __init__(self):\n",
    "        env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "        super().__init__(env)\n",
    "        self.env = env\n",
    "        self.step_n = 0\n",
    "\n",
    "    def reset(self):\n",
    "        state, _ = self.env.reset()\n",
    "        self.step_n = 0\n",
    "        return state\n",
    "\n",
    "    def step(self, action):\n",
    "        state, reward, terminated, truncated, info = self.env.step(action)\n",
    "        done = terminated or truncated\n",
    "        self.step_n += 1\n",
    "        if self.step_n >= 200:\n",
    "            done = True\n",
    "        return state, reward, done, info\n",
    "\n",
    "\n",
    "env = MyWrapper()\n",
    "\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#打印游戏\n",
    "def show():\n",
    "    plt.imshow(env.render())\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 1],\n",
       " tensor([[0.6790],\n",
       "         [0.6861]], grad_fn=<ViewBackward0>),\n",
       " tensor([[0.4162, 0.5838],\n",
       "         [0.4408, 0.5592]], grad_fn=<SoftmaxBackward0>))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "\n",
    "class ModelAction(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = torch.nn.Sequential(\n",
    "                    torch.nn.Linear(4, 128),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Linear(128, 2),\n",
    "                    torch.nn.Softmax(dim=1),\n",
    "                )\n",
    "\n",
    "    def forward(self, state):\n",
    "        prob = self.model(state)  \n",
    "\n",
    "        # 采样动作\n",
    "        action = [random.choices(range(2), weights=p.tolist(), k=1)[0] for p in prob]  # 采样一个动作\n",
    "\n",
    "        # 计算熵\n",
    "        # prob[0, action] 是采样动作 action 的概率\n",
    "        #log_prob = torch.log(prob + 1e-7)  # 避免 log(0) 加小 epsilon\n",
    "        #entropy = -log_prob  # 单个动作的熵贡献，-log π(a|s)\n",
    "\n",
    "        # 改2：离散熵用求和\n",
    "        #[b, 2]\n",
    "        entropy = prob * torch.log(prob + 1e-8)\n",
    "\n",
    "        #所有动作的熵求和\n",
    "        #[b, 2] -> [b, 1]\n",
    "        entropy = -entropy.sum(dim=1, keepdim=True)\n",
    "        # 或者更准确的熵估计（基于整个分布）\n",
    "        # 熵 = -∑ π(a|s) log π(a|s)，可以使用 prob 直接计算期望\n",
    "        #entropy = -torch.sum(prob * torch.log(prob + 1e-7))  # 整个分布的熵\n",
    "\n",
    "        return action, entropy.reshape(-1,1), prob\n",
    "\n",
    "\n",
    "model_action = ModelAction()\n",
    "\n",
    "model_action(torch.randn(2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2539, -0.0166],\n",
       "        [ 0.2044, -0.1752]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ModelValue(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            torch.nn.Linear(5, 128),\n",
    "            torch.nn.ReLU(),#改9：删去一层\n",
    "            # 改4：输出是二维以匹配后面的与prob相乘\n",
    "            torch.nn.Linear(128, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        #[b, 4+1] -> [b, 5]\n",
    "        state = torch.cat([state, action], dim=1)\n",
    "\n",
    "        #[b, 5] -> [b, 1]\n",
    "        return self.sequential(state)\n",
    "\n",
    "\n",
    "model_value1 = ModelValue()\n",
    "model_value2 = ModelValue()\n",
    "\n",
    "model_value_next1 = ModelValue()\n",
    "model_value_next2 = ModelValue()\n",
    "\n",
    "model_value_next1.load_state_dict(model_value1.state_dict())\n",
    "model_value_next2.load_state_dict(model_value2.state_dict())\n",
    "\n",
    "model_value1(torch.randn(2, 4), torch.randn(2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_action(state):\n",
    "    state = torch.FloatTensor(state).reshape(1, 4)\n",
    "    #[1, 4] -> [1, 2]\n",
    "    action, _, __ = model_action(state)\n",
    "\n",
    "    return action\n",
    "\n",
    "\n",
    "get_action([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuchen/Fdisk/miniconda3/envs/RL-py39/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((202, 0), 202)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#样本池\n",
    "datas = []\n",
    "\n",
    "\n",
    "### 改1：要收集足够多的数据\n",
    "#向样本池中添加N条数据,删除M条最古老的数据\n",
    "def update_data():\n",
    "    old_count = len(datas)\n",
    "\n",
    "    #玩到新增了N个数据为止\n",
    "    while len(datas) - old_count < 200:\n",
    "        #初始化游戏\n",
    "        state = env.reset()\n",
    "\n",
    "        #玩到游戏结束为止\n",
    "        over = False\n",
    "        while not over:\n",
    "            #根据当前状态得到一个动作\n",
    "            action = get_action(state)\n",
    "\n",
    "            #执行动作,得到反馈\n",
    "            next_state, reward, over, _ = env.step(action[0])\n",
    "\n",
    "            #记录数据样本\n",
    "            datas.append((state, action, reward, next_state, over))\n",
    "\n",
    "            #更新游戏状态,开始下一个动作\n",
    "            state = next_state\n",
    "\n",
    "    update_count = len(datas) - old_count\n",
    "    drop_count = max(len(datas) - 10000, 0)\n",
    "\n",
    "    #数据上限,超出时从最古老的开始删除\n",
    "    while len(datas) > 10000:\n",
    "        datas.pop(0)\n",
    "\n",
    "    return update_count, drop_count\n",
    "\n",
    "\n",
    "update_data(), len(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_460657/3749404182.py:8: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
      "  state = torch.FloatTensor([i[0] for i in samples]).reshape(-1, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1012,  0.0047, -0.1413, -0.4497],\n",
       "         [-0.1541, -0.7941,  0.2055,  1.4614],\n",
       "         [-0.0629,  0.1687,  0.1089, -0.1926],\n",
       "         [-0.0017, -0.3617,  0.0326,  0.6079],\n",
       "         [ 0.0991,  0.3741, -0.0797, -0.5738]]),\n",
       " tensor([[1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]]),\n",
       " tensor([[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]]),\n",
       " tensor([[ 0.1013,  0.2015, -0.1503, -0.7834],\n",
       "         [-0.1700, -0.9911,  0.2347,  1.8106],\n",
       "         [-0.0595, -0.0278,  0.1051,  0.1324],\n",
       "         [-0.0089, -0.5573,  0.0448,  0.9107],\n",
       "         [ 0.1066,  0.1802, -0.0912, -0.3073]]),\n",
       " tensor([[0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#获取一批数据样本\n",
    "def get_sample():\n",
    "    #从样本池中采样\n",
    "    samples = random.sample(datas, 64)\n",
    "\n",
    "    # 改8： 返回数据类型 action F->L reward:L->F\n",
    "    #[b, 4]\n",
    "    state = torch.FloatTensor([i[0] for i in samples]).reshape(-1, 4)\n",
    "    #[b, 1]\n",
    "    action = torch.LongTensor([i[1] for i in samples]).reshape(-1, 1)\n",
    "    #[b, 1]\n",
    "    reward = torch.FloatTensor([i[2] for i in samples]).reshape(-1, 1)\n",
    "    #[b, 4]\n",
    "    next_state = torch.FloatTensor([i[3] for i in samples]).reshape(-1, 4)\n",
    "    #[b, 1]\n",
    "    over = torch.LongTensor([i[4] for i in samples]).reshape(-1, 1)\n",
    "\n",
    "    return state, action, reward, next_state, over\n",
    "\n",
    "\n",
    "state, action, reward, next_state, over = get_sample()\n",
    "\n",
    "state[:5], action[:5], reward[:5], next_state[:5], over[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython import display\n",
    "\n",
    "\n",
    "def test(play):\n",
    "    #初始化游戏\n",
    "    state = env.reset()\n",
    "\n",
    "    #记录反馈值的和,这个值越大越好\n",
    "    reward_sum = 0\n",
    "\n",
    "    #玩到游戏结束为止\n",
    "    over = False\n",
    "    while not over:\n",
    "        #根据当前状态得到一个动作\n",
    "        action = get_action(state)\n",
    "\n",
    "        #执行动作,得到反馈\n",
    "        state, reward, over, _ = env.step(action[0])\n",
    "        reward_sum += reward\n",
    "\n",
    "        #打印动画\n",
    "        if play and random.random() < 0.2:  #跳帧\n",
    "            display.clear_output(wait=True)\n",
    "            show()\n",
    "\n",
    "    return reward_sum\n",
    "\n",
    "\n",
    "test(play=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_update(model, model_next):\n",
    "    for param, param_next in zip(model.parameters(), model_next.parameters()):\n",
    "        #以一个小的比例更新\n",
    "        value = param_next.data * 0.995 + param.data * 0.005\n",
    "        param_next.data.copy_(value)\n",
    "\n",
    "\n",
    "soft_update(torch.nn.Linear(4, 64), torch.nn.Linear(4, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-4.6052, requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "#这也是一个可学习的参数\n",
    "alpha = torch.tensor(math.log(0.01))\n",
    "alpha.requires_grad = True\n",
    "\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_target(reward, next_state, over):\n",
    "    #首先使用model_action计算动作和动作的熵\n",
    "    #[b, 4] -> [b, 1],[b, 1]\n",
    "    action, entropy, prob= model_action(next_state)\n",
    "\n",
    "    #评估next_state的价值\n",
    "    #[b, 4],[b, 1] -> [b, 1]\n",
    "    action_tensor = torch.tensor(action, dtype=torch.float32).reshape(-1,1)\n",
    "    target1 = model_value_next1(next_state, action_tensor)\n",
    "    target2 = model_value_next2(next_state, action_tensor)\n",
    "\n",
    "    #取价值小的,这是出于稳定性考虑\n",
    "    #[b, 1]\n",
    "    target = torch.min(target1, target2)\n",
    "\n",
    "    # 改5：二维的value和prob结合求其期望\n",
    "    target = (prob * target)\n",
    "    target = target.sum(dim=1, keepdim=True)\n",
    "\n",
    "    #exp和log互为反操作,这里是把alpha还原了\n",
    "    #这里的操作是在target上加上了动作的熵,alpha作为权重系数\n",
    "    #[b, 1] - [b, 1] -> [b, 1]\n",
    "    target += alpha.exp() * entropy\n",
    "\n",
    "    #[b, 1]\n",
    "    target *= 0.99\n",
    "    target *= (1 - over)\n",
    "    target += reward\n",
    "\n",
    "    return target\n",
    "\n",
    "\n",
    "get_target(reward, next_state, over).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0591, grad_fn=<MeanBackward0>),\n",
       " tensor([[0.6865],\n",
       "         [0.6921],\n",
       "         [0.6867],\n",
       "         [0.6893],\n",
       "         [0.6873],\n",
       "         [0.6861],\n",
       "         [0.6884],\n",
       "         [0.6876],\n",
       "         [0.6862],\n",
       "         [0.6881],\n",
       "         [0.6856],\n",
       "         [0.6869],\n",
       "         [0.6866],\n",
       "         [0.6886],\n",
       "         [0.6898],\n",
       "         [0.6876],\n",
       "         [0.6869],\n",
       "         [0.6870],\n",
       "         [0.6833],\n",
       "         [0.6863],\n",
       "         [0.6884],\n",
       "         [0.6866],\n",
       "         [0.6850],\n",
       "         [0.6895],\n",
       "         [0.6867],\n",
       "         [0.6920],\n",
       "         [0.6861],\n",
       "         [0.6861],\n",
       "         [0.6877],\n",
       "         [0.6856],\n",
       "         [0.6902],\n",
       "         [0.6902],\n",
       "         [0.6866],\n",
       "         [0.6870],\n",
       "         [0.6883],\n",
       "         [0.6872],\n",
       "         [0.6871],\n",
       "         [0.6921],\n",
       "         [0.6869],\n",
       "         [0.6867],\n",
       "         [0.6888],\n",
       "         [0.6864],\n",
       "         [0.6865],\n",
       "         [0.6888],\n",
       "         [0.6898],\n",
       "         [0.6868],\n",
       "         [0.6876],\n",
       "         [0.6877],\n",
       "         [0.6856],\n",
       "         [0.6897],\n",
       "         [0.6889],\n",
       "         [0.6864],\n",
       "         [0.6871],\n",
       "         [0.6881],\n",
       "         [0.6872],\n",
       "         [0.6855],\n",
       "         [0.6861],\n",
       "         [0.6901],\n",
       "         [0.6869],\n",
       "         [0.6877],\n",
       "         [0.6881],\n",
       "         [0.6873],\n",
       "         [0.6924],\n",
       "         [0.6884]], grad_fn=<ViewBackward0>))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_loss_action(state):\n",
    "    #计算action和熵\n",
    "    #[b, 4] -> [b, 1],[b, 1]\n",
    "    action, entropy, prob = model_action(state)\n",
    "\n",
    "    #使用两个value网络评估action的价值\n",
    "    #[b, 4],[b, 1] -> [b, 1]\n",
    "    action_tensor = torch.tensor(action, dtype=torch.float32).reshape(-1,1)\n",
    "    value1 = model_value1(state, action_tensor)\n",
    "    value2 = model_value2(state, action_tensor)\n",
    "\n",
    "    #取价值小的,出于稳定性考虑\n",
    "    #[b, 1]\n",
    "    value = torch.min(value1, value2)\n",
    "\n",
    "    #alpha还原后乘以熵,这个值期望的是越大越好,但是这里是计算loss,所以符号取反\n",
    "    #[1] - [b, 1] -> [b, 1]\n",
    "    loss_action = -alpha.exp() * entropy\n",
    "\n",
    "    # 改3：熵求和后变为1x1的了，value也要加权求和\n",
    "    #按概率对value进行加权\n",
    "    value *= prob\n",
    "    value = value.sum(dim=1, keepdim=True)\n",
    "    #减去value,所以value越大越好,这样loss就会越小\n",
    "    loss_action -= value #图片公式里用了V，这里没用到\n",
    "\n",
    "    return loss_action.mean(), entropy\n",
    "\n",
    "\n",
    "get_loss_action(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 406 0.0028979189228266478 9.4\n",
      "10 2450 0.00011433335748733953 9.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 73\u001b[0m\n\u001b[1;32m     69\u001b[0m             test_result \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m([test(play\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m)]) \u001b[39m/\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m     70\u001b[0m             \u001b[39mprint\u001b[39m(epoch, \u001b[39mlen\u001b[39m(datas), alpha\u001b[39m.\u001b[39mexp()\u001b[39m.\u001b[39mitem(), test_result)\n\u001b[0;32m---> 73\u001b[0m train()\n",
      "Cell \u001b[0;32mIn[13], line 51\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m loss_action, entropy \u001b[39m=\u001b[39m get_loss_action(state)\n\u001b[1;32m     50\u001b[0m optimizer_action\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 51\u001b[0m loss_action\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     52\u001b[0m optimizer_action\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     54\u001b[0m \u001b[39m#熵乘以alpha就是alpha的loss\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[39m#[b, 1] -> [1]\u001b[39;00m\n",
      "File \u001b[0;32m~/Fdisk/miniconda3/envs/RL-py39/lib/python3.9/site-packages/torch/_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    639\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    640\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    641\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 648\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    649\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    650\u001b[0m )\n",
      "File \u001b[0;32m~/Fdisk/miniconda3/envs/RL-py39/lib/python3.9/site-packages/torch/autograd/__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    350\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m _engine_run_backward(\n\u001b[1;32m    354\u001b[0m     tensors,\n\u001b[1;32m    355\u001b[0m     grad_tensors_,\n\u001b[1;32m    356\u001b[0m     retain_graph,\n\u001b[1;32m    357\u001b[0m     create_graph,\n\u001b[1;32m    358\u001b[0m     inputs,\n\u001b[1;32m    359\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    360\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    361\u001b[0m )\n",
      "File \u001b[0;32m~/Fdisk/miniconda3/envs/RL-py39/lib/python3.9/site-packages/torch/autograd/graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m     unregister_hooks \u001b[39m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    823\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     \u001b[39mreturn\u001b[39;00m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    825\u001b[0m         t_outputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    826\u001b[0m     )  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m     \u001b[39mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    #改7： 学习率大小\n",
    "    optimizer_action = torch.optim.Adam(model_action.parameters(), lr=1e-3)\n",
    "    optimizer_value1 = torch.optim.Adam(model_value1.parameters(), lr=1e-2)\n",
    "    optimizer_value2 = torch.optim.Adam(model_value2.parameters(), lr=1e-2)\n",
    "\n",
    "    #alpha也是要更新的参数,所以这里要定义优化器\n",
    "    optimizer_alpha = torch.optim.Adam([alpha], lr=1e-2)\n",
    "\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    #训练N次\n",
    "    for epoch in range(100):\n",
    "        #更新N条数据\n",
    "        update_data()\n",
    "\n",
    "        #每次更新过数据后,学习N次\n",
    "        for i in range(200):\n",
    "            #采样一批数据\n",
    "            state, action, reward, next_state, over = get_sample()\n",
    "\n",
    "            #对reward偏移,为了便于训练\n",
    "            reward = (reward + 8) / 8\n",
    "\n",
    "            #计算target,这个target里已经考虑了动作的熵\n",
    "            #[b, 1]\n",
    "            target = get_target(reward, next_state, over)\n",
    "            target = target.detach()\n",
    "\n",
    "            # 改6：取对应动作的value值 [b,2]->[b,1]\n",
    "            #计算两个value\n",
    "            value1 = model_value1(state, action).gather(dim=1, index=action.to(torch.int64))\n",
    "            value2 = model_value2(state, action).gather(dim=1, index=action.to(torch.int64))\n",
    "\n",
    "            #计算两个loss,两个value的目标都是要贴近target\n",
    "            loss_value1 = loss_fn(value1, target)\n",
    "            loss_value2 = loss_fn(value2, target)\n",
    "\n",
    "            #更新参数\n",
    "            optimizer_value1.zero_grad()\n",
    "            loss_value1.backward()\n",
    "            optimizer_value1.step()\n",
    "\n",
    "            optimizer_value2.zero_grad()\n",
    "            loss_value2.backward()\n",
    "            optimizer_value2.step()\n",
    "\n",
    "            #使用model_value计算model_action的loss\n",
    "            loss_action, entropy = get_loss_action(state)\n",
    "            optimizer_action.zero_grad()\n",
    "            loss_action.backward()\n",
    "            optimizer_action.step()\n",
    "\n",
    "            #熵乘以alpha就是alpha的loss\n",
    "            #[b, 1] -> [1]\n",
    "            loss_alpha = (entropy + 1).detach() * alpha.exp()\n",
    "            loss_alpha = loss_alpha.mean()\n",
    "\n",
    "            #更新alpha值\n",
    "            optimizer_alpha.zero_grad()\n",
    "            loss_alpha.backward()\n",
    "            optimizer_alpha.step()\n",
    "\n",
    "            #增量更新next模型\n",
    "            soft_update(model_value1, model_value_next1)\n",
    "            soft_update(model_value2, model_value_next2)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            test_result = sum([test(play=False) for _ in range(10)]) / 10\n",
    "            print(epoch, len(datas), alpha.exp().item(), test_result)\n",
    "\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(play=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL-py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
